# right_hip = keypoints_with_scores[0][0][12]
    # right_knee = keypoints_with_scores[0][0][14]
    # right_ankle = keypoints_with_scores[0][0][16]
    # right_shoulder = keypoints_with_scores[0][0][6]
    # right_elbow = keypoints_with_scores[0][0][8]

     # calculate_angle(right_hip, right_knee, right_ankle, frame)
    # calculate_angle(right_shoulder, right_hip, right_knee, frame)
    # calculate_angle(right_hip, right_shoulder, right_elbow, frame)





from datetime import time
from kivy.uix.screenmanager import ScreenManager, Screen
from kivymd.uix.boxlayout import MDBoxLayout
from kivymd.uix.button import MDRaisedButton, MDRoundFlatButton
from kivy.core.image import Texture
from kivy.uix.camera import Camera
from kivy.uix.image import Image
from kivy.lang import Builder
from kivy.clock import Clock
from kivymd.app import MDApp
from camera import Camera2
from kivy.app import App
import tensorflow as tf
import numpy as np
import cv2

####Functions######
def draw_connections(frame, keypoints, edges, confidence_threshold):
    y, x, c = frame.shape
    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))

    for edge, color in edges.items():
        p1, p2 = edge
        y1, x1, c1 = shaped[p1]
        y2, x2, c2 = shaped[p2]

        if (c1 > confidence_threshold) & (c2 > confidence_threshold):
            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 255, 255), 2)
def calculate_angle(a, b, c, frame):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)

    y, x, z = frame.shape
    first_point = np.squeeze(np.multiply(a, [y, x, 1]))
    center_point = np.squeeze(np.multiply(b, [y, x, 1]))
    last_point = np.squeeze(np.multiply(c, [y, x, 1]))

    ######### calculate angle #########

    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
    angle = np.abs(radians * 180.0 / np.pi)

    if angle > 180.0:
        angle = 360 - angle

    ###################################

    cv2.putText(frame, text=str(int(angle)) + "deg", org=(int(center_point[1]) - 60, int(center_point[0]) + 5),
                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(255, 255, 0),
                thickness=1, lineType=cv2.LINE_AA)
    cv2.circle(frame, (int(center_point[1]), int(center_point[0])), 4, (255, 0, 0), -2)
    cv2.line(frame, (int(first_point[1]), int(first_point[0])), (int(center_point[1]), int(center_point[0])),
             (0, 0, 255), 2)
    cv2.line(frame, (int(center_point[1]), int(center_point[0])), (int(last_point[1]), int(last_point[0])), (0, 0, 255),
             2)
def draw_keypoints(frame, keypoints, confidence_threshold):
    y, x, c = frame.shape
    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))

    for kp in shaped:
        ky, kx, kp_conf = kp
        if kp_conf > confidence_threshold:
            cv2.circle(frame, (int(kx), int(ky)), 4, (0, 255, 0), -1)


EDGES = {
    (0, 1): 'm',
    (0, 2): 'c',
    (1, 3): 'm',
    (2, 4): 'c',
    (0, 5): 'm',
    (0, 6): 'c',
    (5, 7): 'm',
    (7, 9): 'm',
    (6, 8): 'c',
    (8, 10): 'c',
    (5, 6): 'y',
    (5, 11): 'm',
    (6, 12): 'c',
    (11, 12): 'y',
    (11, 13): 'm',
    (13, 15): 'm',
    (12, 14): 'c',
    (14, 16): 'c'
}

#####Loading the model#######
interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_thunder_3.tflite')
interpreter.allocate_tensors()

class WindowManager(ScreenManager):
    pass
class LandingPage(Screen):
    pass
class ResultPage(Screen):
    pass
class AboutPage(Screen):
    pass

class MainPage(Screen):
    pass

class MainApp(MDApp):
    name = "main"
    def build(self):
        self.theme_cls.theme_style = "Dark"
        self.theme_cls.primary_palette = "BlueGray"
        layout = MDBoxLayout(orientation = "vertical")
        self.image = Image()
        layout.add_widget(self.image)
        self.capture_button = MDRoundFlatButton(
            pos_hint= {"center_x": 0.5, "center_y": 0.5},
            text= "Capture"
        )
        layout.add_widget(self.capture_button)
        self.cap = cv2.VideoCapture(0)
        Clock.schedule_interval(self.load_video, 1.0 / 30.0)
        return layout

    def load_video(self, *args):
        ret, img = self.cap.read()
        img = cv2.flip(img, 1)
        frame = img.copy()
        img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 256, 256)
        input_image = tf.cast(img, dtype=tf.float32)

        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()

        interpreter.set_tensor(input_details[0]['index'], np.array(input_image))
        interpreter.invoke()
        keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])
        draw_connections(frame, keypoints_with_scores, EDGES, 0.4)
        draw_keypoints(frame, keypoints_with_scores, 0.4)

        self.image.image_frame = frame
        buffer = cv2.flip(frame, 0).tostring()
        texture = Texture.create(size=(frame.shape[1], frame.shape[0]), colorfmt='bgr')
        texture.blit_buffer(buffer, colorfmt='bgr', bufferfmt='ubyte')
        self.image.texture = texture

if __name__=='__main__':
    MainApp().run()





    WindowManager:
    LandingPage:
        name: "landing"
    AboutPage:
        name: "about"
    ResultPage:
        name: "result"
    MainPage:
        name: "main"

<LandingPage>:
    MDBoxLayout:
        orientation: "vertical"

        MDRoundFlatButton:
            text: "Start"
            on_release: app.root.current = "main"

        MDRoundFlatButton:
            text: "About"
            on_release: app.root.current = "about"

<AboutPage>:
    Screen:
        MDCard:
            size_hint: None, None
            size: 300,400
            pos_hint: {"center_x": 0.5, "center_y": 0.5}
            padding: 25
            spacing: 25
            elevation: 1
            padding_x: 30
            orientation: "vertical"

            MDLabel:
                text: "About"
                font_size: 40
                halign: "center"
                size_hint_y : None
                height: self.texture_size[1]
                padding_y: 15


<ResultPage>:



OLD LAYOUT CODEEEEEEEE


#layout = MDBoxLayout(orientation = "vertical")
        #self.image = Image()
        #self.capture_button = MDRoundFlatButton(
        #    pos_hint= {"center_x": 0.5, "center_y": 0.5},
        #    text="Start",
        #    padding=20
        #)
        #self.md_card = MDCard( size_hint= (None, None),
        #    size=(300,300),
        #    pos_hint={"center_x": 0.5, "center_y": 0.5},
        #    padding=25,
        #    spacing=25,
        #    elevation=1,
        #    orientation="vertical"
        #)
        #layout.add_widget(self.image)
        #layout.add_widget(self.capture_button)
        #layout.add_widget(self.md_card)
        #self.cap = cv2.VideoCapture(0)
        #clock.schedule_interval(self.load_video, 1.0 / 60.0)
        #self.load_video()


load videooooooooo

    def load_video(self, *args):
        ret, img = self.cap.read()
        #img = cv2.imread("normal.jpg")
        img = cv2.flip(img, 1)
        frame = img.copy()
        img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 256, 256)
        input_image = tf.cast(img, dtype=tf.float32)

        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()

        interpreter.set_tensor(input_details[0]['index'], np.array(input_image))
        interpreter.invoke()

        keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])
        draw_connections(frame, keypoints_with_scores, EDGES, 0.4)
        draw_keypoints(frame, keypoints_with_scores, 0.4)

        self.feature_extraction(keypoints_with_scores, frame)

        self.image.image_frame = frame
        buffer = cv2.flip(frame, 0).tostring()
        texture = Texture.create(size=(frame.shape[1], frame.shape[0]), colorfmt='bgr')
        texture.blit_buffer(buffer, colorfmt='bgr', bufferfmt='ubyte')
        self.image.texture = texture



EXTRACT FEATURESSSSSSS

    def feature_extraction(self,keypoints_with_scores, frame):

        # shoulder, elbow and upper hip angles array
        shoulder_angle_array = np.empty(0, dtype=float)
        elbow_angle_array = np.empty(0, dtype=float)
        hip_upper_array = np.empty(0, dtype=float)

        # knee and hip angle array
        knee_angle_array = np.empty(0, dtype=float)
        hip_array = np.empty(0, dtype=float)
        # HIP AND HORIZONTAL KEYPOINT
        right_hip = keypoints_with_scores[0][0][12]
        horizontal_hip = [right_hip[0], right_hip[1] + 0.12, 0.4]

        # UPPER BODY KEYPOINTS
        right_wrist = keypoints_with_scores[0][0][10]
        right_elbow = keypoints_with_scores[0][0][8]
        right_shoulder = keypoints_with_scores[0][0][6]

        # UPPER BODY FEATURES ( hip, shoulder, elbow angles)
        elbow_angle = calculate_angle(right_wrist, right_elbow, right_shoulder, frame)
        shoulder_angle = calculate_angle(right_elbow, right_shoulder, right_hip, frame)
        hip_angle_upper = calculate_angle(horizontal_hip, right_hip, right_shoulder, frame)

        # LOWER BODY KEYPOINTS
        right_knee = keypoints_with_scores[0][0][14]
        right_ankle = keypoints_with_scores[0][0][16]

        # LOWER BODY FEATURES (knee and hip angles)
        knee_angle = calculate_angle(right_hip, right_knee, right_ankle, frame)
        hip_angle_lower = calculate_angle(horizontal_hip, right_hip, right_knee, frame)




####Functions######
def draw_connections(frame, keypoints, edges, confidence_threshold):
    y, x, c = frame.shape
    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))

    for edge, color in edges.items():
        p1, p2 = edge
        y1, x1, c1 = shaped[p1]
        y2, x2, c2 = shaped[p2]

        if (c1 > confidence_threshold) & (c2 > confidence_threshold):
            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 255, 255), 2)
def calculate_angle(a, b, c, frame):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)

    if(a[2] >= 0.4 and b[2] >= 0.4 and c[2] >= 0.4):
        y, x, z = frame.shape
        first_point = np.squeeze(np.multiply(a, [y, x, 1]))
        center_point = np.squeeze(np.multiply(b, [y, x, 1]))
        last_point = np.squeeze(np.multiply(c, [y, x, 1]))

        ######### calculate angle #########

        radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
        angle = np.abs(radians * 180.0 / np.pi)

        if angle > 180.0:
            angle = 360 - angle

        ###################################

        cv2.putText(frame, text=str(int(angle)) + "deg", org=(int(center_point[1]) - 60, int(center_point[0]) + 5),
                    fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(255, 255, 0),
                    thickness=1, lineType=cv2.LINE_AA)
        cv2.circle(frame, (int(center_point[1]), int(center_point[0])), 4, (255, 0, 0), -2)
        cv2.line(frame, (int(first_point[1]), int(first_point[0])), (int(center_point[1]), int(center_point[0])),
                 (0, 0, 255), 2)
        cv2.line(frame, (int(center_point[1]), int(center_point[0])), (int(last_point[1]), int(last_point[0])), (0, 0, 255),
                 2)
def draw_keypoints(frame, keypoints, confidence_threshold):
    y, x, c = frame.shape
    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))

    for kp in shaped:
        ky, kx, kp_conf = kp
        if kp_conf > confidence_threshold:
            cv2.circle(frame, (int(kx), int(ky)), 4, (0, 255, 0), -1)
EDGES = {
    (0, 1): 'm',
    (0, 2): 'c',
    (1, 3): 'm',
    (2, 4): 'c',
    (0, 5): 'm',
    (0, 6): 'c',
    (5, 7): 'm',
    (7, 9): 'm',
    (6, 8): 'c',
    (8, 10): 'c',
    (5, 6): 'y',
    (5, 11): 'm',
    (6, 12): 'c',
    (11, 12): 'y',
    (11, 13): 'm',
    (13, 15): 'm',
    (12, 14): 'c',
    (14, 16): 'c'
}

#####Loading the model#######
interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_thunder_3.tflite')
interpreter.allocate_tensors()







########NEW

import time
from kivymd.uix.boxlayout import MDBoxLayout
from kivymd.uix.button import MDRaisedButton, MDRoundFlatButton
from kivy.core.image import Texture
from kivy.uix.image import Image
from kivy.clock import Clock
from kivy.uix.screenmanager import Screen, ScreenManager
from kivymd.app import MDApp
from kivymd.uix.card import MDCard
from kivy.app import App
import tensorflow as tf
import numpy as np
import cv2
from kivy.core.window import Window
from kivy.properties import StringProperty



class LandingPage(Screen):
    ...
class AboutPage(Screen):
    ...
class CapturePage(Screen):


    def start_up(self):
       start_timer = time.time()
       stop_timer = time.time() + 3


    def capture(self, *args):
        camera = self.ids['camera']
        timestr = time.strftime("%Y%m%d_%H%M%S")
        camera.export_to_png("IMG_{}.png".format(timestr))
        print("Captured")


def analyze(self):
        ...
class ResultPage(Screen):
    ...

class MainApp(MDApp):

    def build(self):
        sm = ScreenManager()
        sm.add_widget(LandingPage(name = "LandingPage"))
        sm.add_widget(AboutPage(name = "AboutPage"))
        sm.add_widget(CapturePage())
        CapturePage.name = "CapturePage"
        sm.add_widget(ResultPage(name="ResultPage"))


        return sm


if __name__=='__main__':
    MainApp().run(